{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Stage 1: Importing dependencies"
      ],
      "metadata": {
        "id": "NDw_jQC3f1za"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Implementation of a Transformer described in the [\"Attention is all you need\" paper](https://papers.nips.cc/paper/7181-attention-is-all-you-need.pdf)"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import math\n",
        "import re\n",
        "import time"
      ],
      "outputs": [],
      "execution_count": 1,
      "metadata": {
        "id": "wWJXHHxyfvUA",
        "gather": {
          "logged": 1683637924736
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install tensorflow==2.* tensorflow-datasets==4.5.2\r\n",
        "#!conda install -y -c anaconda tensorflow==2.* tensorflow-datasets==4.5.2"
      ],
      "outputs": [],
      "execution_count": 2,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1683637925525
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "import tensorflow_datasets as tfds"
      ],
      "outputs": [],
      "execution_count": 3,
      "metadata": {
        "id": "Uv_nm_AugDsV",
        "gather": {
          "logged": 1683637936821
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Stage 2: Data preprocessing"
      ],
      "metadata": {
        "id": "kc7Wf_yngJGw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loading files"
      ],
      "metadata": {
        "id": "2Cv1Pb3xgLkL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We import files previously downloaded from the [European Parliament Proceedings Parallel Corpus 1996-2011](https://www.statmt.org/europarl/) including the corpus and the nonbreaking prefixes for both languages"
      ],
      "metadata": {
        "id": "Y-X9aj9IgPbv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"data/europarl-v7.es-en.en\",\n",
        "          mode='r',\n",
        "          encoding=\"utf-8\") as f:\n",
        "    europarl_en = f.read()\n",
        "with open(\"data/europarl-v7.es-en.es\",\n",
        "          mode='r',\n",
        "          encoding=\"utf-8\") as f:\n",
        "    europarl_es = f.read()\n",
        "with open(\"data/nonbreaking_prefix.en\",\n",
        "          mode='r',\n",
        "          encoding=\"utf-8\") as f:\n",
        "    non_breaking_prefix_en = f.read()\n",
        "with open(\"data/nonbreaking_prefix.es\",\n",
        "          mode='r',\n",
        "          encoding=\"utf-8\") as f:\n",
        "    non_breaking_prefix_es = f.read()\n",
        "\n",
        "print(europarl_en[:25])\n",
        "print(europarl_es[:25])"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Resumption of the session\nReanudación del período d\n"
        }
      ],
      "execution_count": 4,
      "metadata": {
        "id": "XMBwaQJjgZjp",
        "gather": {
          "logged": 1683637953103
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Cleaning data"
      ],
      "metadata": {
        "id": "ZzAviIErhKEH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Getting the non_breaking_prefixes as a clean list of words with a point at the end so it is easier to use."
      ],
      "metadata": {
        "id": "VoBBMXpUhM8U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "non_breaking_prefix_en = non_breaking_prefix_en.split(\"\\n\")\n",
        "non_breaking_prefix_en = [' ' + pref + '.' for pref in non_breaking_prefix_en if not pref.startswith('#')]\n",
        "non_breaking_prefix_es = non_breaking_prefix_es.split(\"\\n\")\n",
        "non_breaking_prefix_es = [' ' + pref + '.' for pref in non_breaking_prefix_es if not pref.startswith('#')]\n",
        "\n",
        "print(non_breaking_prefix_en[:3])\n",
        "print(non_breaking_prefix_es[:3])"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "[' .', ' A.', ' B.']\n[' .', ' A.', ' B.']\n"
        }
      ],
      "execution_count": 5,
      "metadata": {
        "id": "NBaz0Y-uhLQA",
        "gather": {
          "logged": 1683637953877
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will need each word and other symbol that we want to keep to be in lower case and separated by spaces so we can \"tokenize\" them."
      ],
      "metadata": {
        "id": "zRy8a6WYhl7Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "corpus_en = europarl_en\n",
        "for prefix in non_breaking_prefix_en:\n",
        "    corpus_en = corpus_en.replace(prefix, prefix + \"###\")           # prefix replaced -> prefix###\n",
        "corpus_en = re.sub(r\"\\.(?=[0-9]|[a-z]|[A-Z])\", \".###\", corpus_en)   # Dot not followed by space -> .###\n",
        "corpus_en = re.sub(r\"\\.###\", '', corpus_en)                         # Remove ending sentence point\n",
        "corpus_en = re.sub(r\"  +\", ' ', corpus_en)                          # Replace multiple spaces with one single space\n",
        "corpus_en = corpus_en.split(\"\\n\")                                   # Split each line\n",
        "\n",
        "corpus_es = europarl_es\n",
        "for prefix in non_breaking_prefix_es:\n",
        "    corpus_es = corpus_es.replace(prefix, prefix + \"###\")           # prefix replaced -> prefix###\n",
        "corpus_es = re.sub(r\"\\.(?=[0-9]|[a-z]|[A-Z])\", \".###\", corpus_es)   # Dot not followed by space -> .###\n",
        "corpus_es = re.sub(r\"\\.###\", '', corpus_es)                         # Remove ending sentence point\n",
        "corpus_es = re.sub(r\"  +\", ' ', corpus_es)                          # Replace multiple spaces with one single space\n",
        "corpus_es = corpus_es.split(\"\\n\")                                   # Split each line"
      ],
      "outputs": [],
      "execution_count": 6,
      "metadata": {
        "id": "v-F5KlmMhttk",
        "gather": {
          "logged": 1683638052022
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tokenizing text\r\n",
        "\r\n",
        "Transform each work in a number. Using SubwordTextEncoder. Using an aproximate number of words in target_vocab_size 2**13. Using a lower number of words can improve the model."
      ],
      "metadata": {
        "id": "l0gJoNgL02yY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer_en = tfds.deprecated.text.SubwordTextEncoder.build_from_corpus(\n",
        "    corpus_en, target_vocab_size=2**13)\n",
        "tokenizer_es = tfds.deprecated.text.SubwordTextEncoder.build_from_corpus(\n",
        "    corpus_es, target_vocab_size=2**13)\n",
        "\n",
        "print(tokenizer_en.decode([1,200,3000]))\n",
        "print(tokenizer_es.decode([1,200,3000]))\n",
        "\n",
        "print(tokenizer_en.encode(\"Hi, how are you?\"))\n",
        "print(tokenizer_en.encode(\"Hola, cómo estás?\"))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "the situation Perhaps \nde sistema juego \n[6181, 2, 172, 17, 362, 8005]\n[2191, 796, 2, 8041, 3963, 1835, 7974, 1814, 3235, 8057, 8005]\n"
        }
      ],
      "execution_count": 7,
      "metadata": {
        "id": "9_nBLPM00Rhy",
        "gather": {
          "logged": 1683638654027
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "VOCAB_SIZE_EN = tokenizer_en.vocab_size + 2\n",
        "VOCAB_SIZE_ES = tokenizer_es.vocab_size + 2\n",
        "\n",
        "print(VOCAB_SIZE_EN, VOCAB_SIZE_ES)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "8200 8227\n"
        }
      ],
      "execution_count": 8,
      "metadata": {
        "id": "8ktLO0eD1O20",
        "gather": {
          "logged": 1683638654619
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = [[VOCAB_SIZE_EN-2] + tokenizer_en.encode(sentence) + [VOCAB_SIZE_EN-1]\n",
        "          for sentence in corpus_en]\n",
        "outputs = [[VOCAB_SIZE_ES-2] + tokenizer_es.encode(sentence) + [VOCAB_SIZE_ES-1]\n",
        "          for sentence in corpus_es]\n",
        "\n",
        "print(inputs[0])\n",
        "print(outputs[0])"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "[8198, 4378, 999, 2622, 3, 1, 2509, 8199]\n[8225, 5967, 1688, 265, 52, 12, 683, 1, 3427, 1377, 8226]\n"
        }
      ],
      "execution_count": 9,
      "metadata": {
        "id": "VVqHegbp1XnK",
        "gather": {
          "logged": 1683638840973
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Remove too long sentences"
      ],
      "metadata": {
        "id": "nuaPXaDg1qDQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Length before removing long sentences\", len(inputs), len(outputs))\n",
        "\n",
        "MAX_LENGTH = 20\n",
        "idx_to_remove = [count for count, sent in enumerate(inputs)\n",
        "                 if len(sent) > MAX_LENGTH]\n",
        "for idx in reversed(idx_to_remove):\n",
        "    del inputs[idx]\n",
        "    del outputs[idx]\n",
        "idx_to_remove = [count for count, sent in enumerate(outputs)\n",
        "                 if len(sent) > MAX_LENGTH]\n",
        "for idx in reversed(idx_to_remove):\n",
        "    del inputs[idx]\n",
        "    del outputs[idx]\n",
        "\n",
        "print(\"Length after removing long sentences\", len(inputs), len(outputs))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Length before removing long sentences 1965735 1965735\nLength after removing long sentences 411696 411696\n"
        }
      ],
      "execution_count": 10,
      "metadata": {
        "id": "efQb8K6O1rfc",
        "gather": {
          "logged": 1683639079384
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Inputs/outputs creation"
      ],
      "metadata": {
        "id": "dUxUThRH2HFf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "As we train with batches, we need each input to have the same length. We pad with the appropriate token, and we will make sure this padding token doesn't interfere with our training later."
      ],
      "metadata": {
        "id": "xvPC9nPN2M6B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = tf.keras.preprocessing.sequence.pad_sequences(inputs,\n",
        "                                                       value=0,\n",
        "                                                       padding=\"post\",\n",
        "                                                       maxlen=MAX_LENGTH)\n",
        "outputs = tf.keras.preprocessing.sequence.pad_sequences(outputs,\n",
        "                                                        value=0,\n",
        "                                                        padding=\"post\",\n",
        "                                                        maxlen=MAX_LENGTH)\n",
        "\n",
        "print(inputs[0])\n",
        "print(outputs[0])"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "[8198 4378  999 2622    3    1 2509 8199    0    0    0    0    0    0\n    0    0    0    0    0    0]\n[8225 5967 1688  265   52   12  683    1 3427 1377 8226    0    0    0\n    0    0    0    0    0    0]\n"
        }
      ],
      "execution_count": 11,
      "metadata": {
        "id": "sOE-P2lT2MQp",
        "gather": {
          "logged": 1683639082611
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 64\n",
        "BUFFER_SIZE = 20000\n",
        "\n",
        "dataset = tf.data.Dataset.from_tensor_slices((inputs, outputs))\n",
        "\n",
        "dataset = dataset.cache()\n",
        "dataset = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE)\n",
        "dataset = dataset.prefetch(tf.data.experimental.AUTOTUNE)\n",
        "\n",
        "print(dataset)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "<PrefetchDataset shapes: ((None, 20), (None, 20)), types: (tf.int32, tf.int32)>\n"
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "2023-05-09 13:31:22.368490: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n2023-05-09 13:31:23.680352: E tensorflow/stream_executor/cuda/cuda_driver.cc:313] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n2023-05-09 13:31:23.680413: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (computetarget): /proc/driver/nvidia/version does not exist\n2023-05-09 13:31:23.686942: I tensorflow/core/platform/cpu_feature_guard.cc:143] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA\n2023-05-09 13:31:23.766438: I tensorflow/core/platform/profile_utils/cpu_utils.cc:102] CPU Frequency: 2593905000 Hz\n2023-05-09 13:31:23.768982: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fc588000b60 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n2023-05-09 13:31:23.769012: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n"
        }
      ],
      "execution_count": 12,
      "metadata": {
        "id": "uINRFhOm2mu1",
        "gather": {
          "logged": 1683639084468
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Stage 3: Model building"
      ],
      "metadata": {
        "id": "Wn2w4DqH288u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Positional Encoding"
      ],
      "metadata": {
        "id": "BcFBxDRZ2_WT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Positional encoding formulae:\n",
        "\n",
        "$PE_{(pos, 2i)} = \\sin(pos/n^{2i/dmodel})$\n",
        "\n",
        "$PE_{(pos, 2i+1)} = \\cos(pos/n^{2i/dmodel})$\n",
        "\n",
        "\n",
        "**Here**:\n",
        "\n",
        "pos: Position of an object in the input sequence, \n",
        "\n",
        "dmodel: Dimension of the output embedding space\n",
        "\n",
        "P(k,j): Position function for mapping a position in the input sequence to index of the positional matrix\n",
        "\n",
        "n: User-defined scalar, set to 10,000 by the authors of Attention Is All You Need.\n",
        "\n",
        "i: Used for mapping to column indices, with a single value of maps to both sine and cosine functions\n",
        "\n",
        "__In the above expression, you can see that even positions correspond to a sine function and odd positions correspond to cosine functions.__\n",
        "\n",
        "More details in the following [article](https://machinelearningmastery.com/a-gentle-introduction-to-positional-encoding-in-transformer-models-part-1/)"
      ],
      "metadata": {
        "id": "v0aOFAzp3Buh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class PositionalEncoding(layers.Layer):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(PositionalEncoding, self).__init__()\n",
        "    \n",
        "    def get_angles(self, pos, i, d_model, n=10000.): # pos: (seq_length, 1) i: (1, d_model)\n",
        "        angles = 1 / np.power(n, (2*(i//2))/np.float32(d_model))\n",
        "        return pos * angles # (seq_length, d_model)\n",
        "    \n",
        "    def call(self, inputs):\n",
        "        seq_length = inputs.shape.as_list()[-2]\n",
        "        d_model = inputs.shape.as_list()[-1]\n",
        "        angles = self.get_angles(np.arange(seq_length)[:, np.newaxis],\n",
        "                                 np.arange(d_model)[np.newaxis, :],\n",
        "                                 d_model)\n",
        "        angles[:, 0::2] = np.sin(angles[:, 0::2])\n",
        "        angles[:, 1::2] = np.cos(angles[:, 1::2])\n",
        "        pos_encoding = angles[np.newaxis, ...]\n",
        "\n",
        "        return inputs + tf.cast(pos_encoding, tf.float32)"
      ],
      "outputs": [],
      "execution_count": 13,
      "metadata": {
        "id": "dr0S1uBX2-_i",
        "gather": {
          "logged": 1683639084983
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Attention"
      ],
      "metadata": {
        "id": "uCkTpS5X4oSw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Attention computation"
      ],
      "metadata": {
        "id": "LOXSznTT4r0C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "$Attention(Q, K, V) = \\text{softmax}\\left(\\frac{QK^T}{\\sqrt{d_k}}\\right)V$\r\n",
        "\r\n",
        "![Attention Image](imgs/Dot_Product_Attention.png)"
      ],
      "metadata": {
        "id": "VilQe5gT4uA3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def scaled_dot_product_attention(queries, keys, values, mask):\n",
        "    product = tf.matmul(queries, keys, transpose_b=True)\n",
        "\n",
        "    keys_dim = tf.cast(tf.shape(keys)[-1], tf.float32)\n",
        "    scaled_product = product / tf.math.sqrt(keys_dim)\n",
        "\n",
        "    if mask is not None:\n",
        "        scaled_product += (mask * -1e9)\n",
        "    \n",
        "    attention = tf.matmul(tf.nn.softmax(scaled_product, axis=-1), values)\n",
        "\n",
        "    return attention"
      ],
      "outputs": [],
      "execution_count": 14,
      "metadata": {
        "id": "LO49thja5EaF",
        "gather": {
          "logged": 1683639085472
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Multi-head attention sublayer\r\n",
        "\r\n",
        "![Multi Head Attention Image](imgs/Multi_Head_Attention.png)"
      ],
      "metadata": {
        "id": "eYhP6g5i5cba"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MultiHeadAttention(layers.Layer):\n",
        "\n",
        "    def __init__(self, nb_proj):\n",
        "        super(MultiHeadAttention, self).__init__()\n",
        "        self.nb_proj = nb_proj\n",
        "    \n",
        "    def build(self, input_shape):\n",
        "        self.d_model = input_shape[-1]\n",
        "        assert self.d_model % self.nb_proj == 0\n",
        "\n",
        "        self.d_proj = self.d_model // self.nb_proj\n",
        "\n",
        "        self.query_lin = layers.Dense(units=self.d_model)\n",
        "        self.key_lin = layers.Dense(units=self.d_model)\n",
        "        self.value_lin = layers.Dense(units=self.d_model)\n",
        "\n",
        "        self.final_lin = layers.Dense(units=self.d_model)\n",
        "    \n",
        "    def split_proj(self, inputs, batch_size): # inputs: (batch_size, seq_length, d_model)\n",
        "        shape = (batch_size,\n",
        "                 -1,\n",
        "                 self.nb_proj,\n",
        "                 self.d_proj)\n",
        "        splited_inputs = tf.reshape(inputs, shape=shape) # (batch_size, seq_length, nb_proj, d_proj)\n",
        "        \n",
        "        return tf.transpose(splited_inputs, perm=[0, 2, 1, 3]) # (batch_size, nb_proj, seq_length, d_proj)\n",
        "    \n",
        "    def call(self, queries, keys, values, mask):\n",
        "        batch_size = tf.shape(queries)[0]\n",
        "\n",
        "        queries = self.query_lin(queries)\n",
        "        keys = self.key_lin(keys)\n",
        "        values = self.value_lin(values)\n",
        "\n",
        "        queries = self.split_proj(queries, batch_size)\n",
        "        keys = self.split_proj(keys, batch_size)\n",
        "        values = self.split_proj(values, batch_size)\n",
        "\n",
        "        attention = scaled_dot_product_attention(queries, keys, values, mask)\n",
        "\n",
        "        attention = tf.transpose(attention, perm=[0, 2, 1, 3])\n",
        "\n",
        "        concat_attention = tf.reshape(attention,\n",
        "                                      shape=(batch_size, -1, self.d_model))\n",
        "        \n",
        "        outputs = self.final_lin(concat_attention)\n",
        "\n",
        "        return outputs"
      ],
      "outputs": [],
      "execution_count": 15,
      "metadata": {
        "id": "EsK2rhm95eRx",
        "gather": {
          "logged": 1683639085945
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Encoder\r\n",
        "\r\n",
        "![Encoder Image](imgs/Encoder.png)"
      ],
      "metadata": {
        "id": "a88reCtV7Vo-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class EncoderLayer(layers.Layer):\n",
        "\n",
        "    def __init__(self, FFN_units, nb_proj, dropout):\n",
        "        super(EncoderLayer, self).__init__()\n",
        "        self.FFN_units = FFN_units\n",
        "        self.nb_proj = nb_proj\n",
        "        self.dropout = dropout\n",
        "    \n",
        "    def build(self, input_shape):\n",
        "        self.d_model = input_shape[-1]\n",
        "\n",
        "        self.multi_head_attention = MultiHeadAttention(self.nb_proj)\n",
        "        self.dropout_1 = layers.Dropout(rate=self.dropout)\n",
        "        self.norm_1 = layers.LayerNormalization(epsilon=1e-6)\n",
        "\n",
        "        self.dense_1 = layers.Dense(units=self.FFN_units, activation=\"relu\")\n",
        "        self.dense_2 = layers.Dense(units=self.d_model)\n",
        "        self.dropout_2 = layers.Dropout(rate=self.dropout)\n",
        "        self.norm_2 = layers.LayerNormalization(epsilon=1e-6)\n",
        "    \n",
        "    def call(self, inputs, mask, training):\n",
        "        attention = self.multi_head_attention(inputs,\n",
        "                                              inputs,\n",
        "                                              inputs,\n",
        "                                              mask)\n",
        "        attention = self.dropout_1(attention, training=training)\n",
        "        attention = self.norm_1(attention + inputs)\n",
        "\n",
        "        outputs = self.dense_1(attention)\n",
        "        outputs = self.dense_2(outputs)\n",
        "        outputs = self.dropout_2(outputs, training=training)\n",
        "        outputs = self.norm_2(outputs + attention)\n",
        "\n",
        "        return outputs"
      ],
      "outputs": [],
      "execution_count": 16,
      "metadata": {
        "id": "Q_wCHJAQ7XZu",
        "gather": {
          "logged": 1683639086368
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Encoder(layers.Layer):\n",
        "\n",
        "    def __init__(self,\n",
        "                 nb_layers,\n",
        "                 FFN_units,\n",
        "                 nb_proj,\n",
        "                 dropout,\n",
        "                 vocab_size,\n",
        "                 d_model,\n",
        "                 name=\"encoder\"):\n",
        "        super(Encoder, self).__init__(name=name)\n",
        "        self.nb_layers = nb_layers\n",
        "        self.d_model = d_model\n",
        "\n",
        "        self.embedding = layers.Embedding(vocab_size, d_model)\n",
        "        self.pos_encoding = PositionalEncoding()\n",
        "        self.dropout = layers.Dropout(rate=dropout)\n",
        "        self.enc_layers = [EncoderLayer(FFN_units,\n",
        "                                        nb_proj,\n",
        "                                        dropout)\n",
        "                           for _ in range(nb_layers)]\n",
        "    \n",
        "    def call(self, inputs, mask, training):\n",
        "        outputs = self.embedding(inputs)\n",
        "        outputs *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
        "        outputs = self.pos_encoding(outputs)\n",
        "        outputs = self.dropout(outputs, training)\n",
        "\n",
        "        for i in range(self.nb_layers):\n",
        "            outputs = self.enc_layers[i](outputs, mask, training)\n",
        "        \n",
        "        return outputs"
      ],
      "outputs": [],
      "execution_count": 17,
      "metadata": {
        "id": "n6QNvI518mpG",
        "gather": {
          "logged": 1683639086807
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Decoder\r\n",
        "\r\n",
        "![Decoder Image](imgs/Decoder.jpg)"
      ],
      "metadata": {
        "id": "OFCrh2G_-mKx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DecoderLayer(layers.Layer):\n",
        "\n",
        "    def __init__(self, FFN_units, nb_proj, dropout):\n",
        "        super(DecoderLayer, self).__init__()\n",
        "        self.FFN_units = FFN_units\n",
        "        self.nb_proj = nb_proj\n",
        "        self.dropout = dropout\n",
        "    \n",
        "    def build(self, input_shape):\n",
        "        self.d_model = input_shape[-1]\n",
        "\n",
        "        self.multi_head_attention_1 = MultiHeadAttention(self.nb_proj)\n",
        "        self.dropout_1 = layers.Dropout(rate=self.dropout)\n",
        "        self.norm_1 = layers.LayerNormalization(epsilon=1e-6)\n",
        "\n",
        "        self.multi_head_attention_2 = MultiHeadAttention(self.nb_proj)\n",
        "        self.dropout_2 = layers.Dropout(rate=self.dropout)\n",
        "        self.norm_2 = layers.LayerNormalization(epsilon=1e-6)\n",
        "\n",
        "        self.dense_1 = layers.Dense(units=self.FFN_units, activation=\"relu\")\n",
        "        self.dense_2 = layers.Dense(units=self.d_model)\n",
        "        self.dropout_3 = layers.Dropout(rate=self.dropout)\n",
        "        self.norm_3 = layers.LayerNormalization(epsilon=1e-6)\n",
        "    \n",
        "    def call(self, inputs, enc_outputs, mask_1, mask_2, training):\n",
        "        attention = self.multi_head_attention_1(inputs,\n",
        "                                                inputs,\n",
        "                                                inputs,\n",
        "                                                mask_1)\n",
        "        attention = self.dropout_1(attention, training=training)\n",
        "        attention = self.norm_1(attention + inputs)\n",
        "\n",
        "        attention_2 = self.multi_head_attention_2(attention,\n",
        "                                                  enc_outputs,\n",
        "                                                  enc_outputs,\n",
        "                                                  mask_2)\n",
        "        attention_2 = self.dropout_2(attention_2, training=training)\n",
        "        attention_2 = self.norm_2(attention_2 + attention)\n",
        "\n",
        "        outputs = self.dense_1(attention_2)\n",
        "        outputs = self.dense_2(outputs)\n",
        "        outputs = self.dropout_3(outputs, training=training)\n",
        "        outputs = self.norm_3(outputs + attention_2)\n",
        "\n",
        "        return outputs"
      ],
      "outputs": [],
      "execution_count": 18,
      "metadata": {
        "id": "bofPBDZ0-nQ7",
        "gather": {
          "logged": 1683639087349
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Decoder(layers.Layer):\n",
        "\n",
        "    def __init__(self,\n",
        "                 nb_layers,\n",
        "                 FFN_units,\n",
        "                 nb_proj,\n",
        "                 dropout,\n",
        "                 vocab_size,\n",
        "                 d_model,\n",
        "                 name=\"decoder\"):\n",
        "        super(Decoder, self).__init__(name=name)\n",
        "        self.nb_layers = nb_layers\n",
        "        self.d_model = d_model\n",
        "\n",
        "        self.embedding = layers.Embedding(vocab_size, d_model)\n",
        "        self.pos_encoding = PositionalEncoding()\n",
        "        self.dropout = layers.Dropout(rate=dropout)\n",
        "        self.dec_layers = [DecoderLayer(FFN_units,\n",
        "                                        nb_proj,\n",
        "                                        dropout)\n",
        "                           for _ in range(nb_layers)]\n",
        "    \n",
        "    def call(self, inputs, enc_outputs, mask_1, mask_2, training):\n",
        "        outputs = self.embedding(inputs)\n",
        "        outputs *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
        "        outputs = self.pos_encoding(outputs)\n",
        "        outputs = self.dropout(outputs, training)\n",
        "\n",
        "        for i in range(self.nb_layers):\n",
        "            outputs = self.dec_layers[i](outputs,\n",
        "                                         enc_outputs,\n",
        "                                         mask_1,\n",
        "                                         mask_2,\n",
        "                                         training)\n",
        "        \n",
        "        return outputs"
      ],
      "outputs": [],
      "execution_count": 19,
      "metadata": {
        "id": "X3hoLUqE_1HJ",
        "gather": {
          "logged": 1683639087858
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Transformer\r\n",
        "\r\n",
        "![Transformer Image](imgs/Transformer.png)"
      ],
      "metadata": {
        "id": "pf_YD4anAbfb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Transformer(tf.keras.Model):\n",
        "\n",
        "    def __init__(self,\n",
        "                 vocab_size_enc,\n",
        "                 vocab_size_dec,\n",
        "                 d_model,\n",
        "                 nb_layers,\n",
        "                 FFN_units,\n",
        "                 nb_proj,\n",
        "                 dropout,\n",
        "                 name=\"transformer\"):\n",
        "        super(Transformer, self).__init__(name=name)\n",
        "\n",
        "        self.encoder = Encoder(nb_layers,\n",
        "                               FFN_units,\n",
        "                               nb_proj,\n",
        "                               dropout,\n",
        "                               vocab_size_enc,\n",
        "                               d_model)\n",
        "        self.decoder = Decoder(nb_layers,\n",
        "                               FFN_units,\n",
        "                               nb_proj,\n",
        "                               dropout,\n",
        "                               vocab_size_dec,\n",
        "                               d_model)\n",
        "        self.last_linear = layers.Dense(units=vocab_size_dec)\n",
        "    \n",
        "    def create_padding_mask(self, seq): # seq: (batch_size, seq_length)\n",
        "        mask = tf.cast(tf.math.equal(seq, 0), tf.float32)\n",
        "        return mask[:, tf.newaxis, tf.newaxis, :]\n",
        "\n",
        "    def create_look_ahead_mask(self, seq):\n",
        "        seq_len = tf.shape(seq)[1]\n",
        "        look_ahead_mask = 1 - tf.linalg.band_part(tf.ones((seq_len, seq_len)), -1, 0)\n",
        "        return look_ahead_mask\n",
        "    \n",
        "    def call(self, enc_inputs, dec_inputs, training):\n",
        "        enc_mask = self.create_padding_mask(enc_inputs)\n",
        "        dec_mask_1 = tf.maximum(\n",
        "            self.create_padding_mask(dec_inputs),\n",
        "            self.create_look_ahead_mask(dec_inputs)\n",
        "        )\n",
        "        dec_mask_2 = self.create_padding_mask(enc_inputs)\n",
        "\n",
        "        enc_outputs = self.encoder(enc_inputs, enc_mask, training)\n",
        "        dec_outputs = self.decoder(dec_inputs,\n",
        "                                   enc_outputs,\n",
        "                                   dec_mask_1,\n",
        "                                   dec_mask_2,\n",
        "                                   training)\n",
        "        \n",
        "        outputs = self.last_linear(dec_outputs)\n",
        "\n",
        "        return outputs"
      ],
      "outputs": [],
      "execution_count": 20,
      "metadata": {
        "id": "NTmNakXjAc7U",
        "gather": {
          "logged": 1683639088362
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Stage 4: Application"
      ],
      "metadata": {
        "id": "mIBSpVE_B9NA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training\r\n",
        "\r\n",
        "The recomended parameters in the paper are commented next to the ones used for this test."
      ],
      "metadata": {
        "id": "5JYN0U3NCChb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tf.keras.backend.clear_session()\n",
        "\n",
        "# Hyper-parameters\n",
        "D_MODEL = 128 # 512\n",
        "NB_LAYERS = 4 # 6\n",
        "FFN_UNITS = 512 # 2048\n",
        "NB_PROJ = 8 # 8\n",
        "DROPOUT = 0.1 # 0.1\n",
        "\n",
        "transformer = Transformer(vocab_size_enc=VOCAB_SIZE_EN,\n",
        "                          vocab_size_dec=VOCAB_SIZE_ES,\n",
        "                          d_model=D_MODEL,\n",
        "                          nb_layers=NB_LAYERS,\n",
        "                          FFN_units=FFN_UNITS,\n",
        "                          nb_proj=NB_PROJ,\n",
        "                          dropout=DROPOUT)"
      ],
      "outputs": [],
      "execution_count": 21,
      "metadata": {
        "id": "ycc6XrOfCAgN",
        "gather": {
          "logged": 1683639088946
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Set loss function, train loss and train accuracy"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True,\n",
        "                                                            reduction=\"none\")\n",
        "def loss_function(target, pred):\n",
        "    mask = tf.math.logical_not(tf.math.equal(target, 0)) \n",
        "    loss_ = loss_object(target, pred)                       # Compute the standard loss without reduction\n",
        "\n",
        "    mask = tf.cast(mask, dtype=loss_.dtype)                 # Make sures values in mask and loss are the same type\n",
        "    loss_ *= mask                                           # Apply mask\n",
        "\n",
        "    return tf.reduce_mean(loss_)                            # Apply reduction\n",
        "\n",
        "train_loss = tf.keras.metrics.Mean(name=\"train_loss\")\n",
        "train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name=\"train_accuracy\")"
      ],
      "outputs": [],
      "execution_count": 22,
      "metadata": {
        "id": "ZYW49iYZCjds",
        "gather": {
          "logged": 1683639089640
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Adam optimizer with custom learning rate described in the paper"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
        "\n",
        "    def __init__(self, d_model, warmup_steps=4000):\n",
        "        super(CustomSchedule, self).__init__()\n",
        "\n",
        "        self.d_model = tf.cast(d_model, tf.float32)\n",
        "        self.warmup_steps = warmup_steps\n",
        "    \n",
        "    def __call__(self, step):\n",
        "        arg1 = tf.math.rsqrt(step)\n",
        "        arg2 = step * (self.warmup_steps**-1.5)\n",
        "\n",
        "        return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)\n",
        "    \n",
        "learning_rate = CustomSchedule(D_MODEL)\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate,\n",
        "                                     beta_1=0.9,\n",
        "                                     beta_2=0.98,\n",
        "                                     epsilon=1e-9)"
      ],
      "outputs": [],
      "execution_count": 23,
      "metadata": {
        "id": "lzRVfJW_DGHG",
        "gather": {
          "logged": 1683639090150
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint_path = \"data/\"\n",
        "\n",
        "ckpt = tf.train.Checkpoint(transformer=transformer,\n",
        "                           optimizer=optimizer)\n",
        "\n",
        "ckpt_manager = tf.train.CheckpointManager(ckpt, checkpoint_path, max_to_keep=5)\n",
        "\n",
        "if ckpt_manager.latest_checkpoint:\n",
        "    ckpt.restore(ckpt_manager.latest_checkpoint)\n",
        "    print(\"Latest checkpoint restored!\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Latest checkpoint restored!\n"
        }
      ],
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pbxJnPFNEUgt",
        "outputId": "6dfc2f5b-8ae6-4cd4-aa00-398644df2eb5",
        "gather": {
          "logged": 1683644733942
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 10\n",
        "for epoch in range(EPOCHS):\n",
        "    print(\"Start of epoch {}\".format(epoch+1))\n",
        "    start = time.time()\n",
        "\n",
        "    train_loss.reset_states()\n",
        "    train_accuracy.reset_states()\n",
        "\n",
        "    for (batch, (enc_inputs, targets)) in enumerate(dataset):\n",
        "        dec_inputs = targets[:, :-1]\n",
        "        dec_outputs_real = targets[:, 1:]\n",
        "        with tf.GradientTape() as tape:\n",
        "            predictions = transformer(enc_inputs, dec_inputs, True)\n",
        "            loss = loss_function(dec_outputs_real, predictions)\n",
        "        \n",
        "        gradients = tape.gradient(loss, transformer.trainable_variables)\n",
        "        optimizer.apply_gradients(zip(gradients, transformer.trainable_variables))\n",
        "\n",
        "        train_loss(loss)\n",
        "        train_accuracy(dec_outputs_real, predictions)\n",
        "\n",
        "        if batch % 50 == 0:\n",
        "            print(\"Epoch {} Batch {} Loss {:.4f} Accuracy {:.4f}\".format(\n",
        "                epoch+1, batch, train_loss.result(), train_accuracy.result()))\n",
        "    \n",
        "    ckpt_save_path = ckpt_manager.save()\n",
        "    print(\"Saving checkpont for epoch {} at {}\".format(epoch+1, ckpt_save_path))\n",
        "    print(\"time taken for 1 epoch: {} secs\\n\".format(time.time() - start))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Start of epoch 1\nEpoch 1 Batch 0 Loss 1.1361 Accuracy 0.4597\nEpoch 1 Batch 50 Loss 1.0939 Accuracy 0.4521\nEpoch 1 Batch 100 Loss 1.1022 Accuracy 0.4565\nEpoch 1 Batch 150 Loss 1.1014 Accuracy 0.4571\nEpoch 1 Batch 200 Loss 1.0998 Accuracy 0.4579\nEpoch 1 Batch 250 Loss 1.0961 Accuracy 0.4577\nEpoch 1 Batch 300 Loss 1.0969 Accuracy 0.4577\nEpoch 1 Batch 350 Loss 1.0941 Accuracy 0.4580\nEpoch 1 Batch 400 Loss 1.0907 Accuracy 0.4578\nEpoch 1 Batch 450 Loss 1.0880 Accuracy 0.4575\nEpoch 1 Batch 500 Loss 1.0859 Accuracy 0.4575\nEpoch 1 Batch 550 Loss 1.0845 Accuracy 0.4575\nEpoch 1 Batch 600 Loss 1.0853 Accuracy 0.4578\nEpoch 1 Batch 650 Loss 1.0854 Accuracy 0.4572\nEpoch 1 Batch 700 Loss 1.0849 Accuracy 0.4580\nEpoch 1 Batch 750 Loss 1.0839 Accuracy 0.4587\nEpoch 1 Batch 800 Loss 1.0795 Accuracy 0.4594\nEpoch 1 Batch 850 Loss 1.0743 Accuracy 0.4604\nEpoch 1 Batch 900 Loss 1.0687 Accuracy 0.4614\nEpoch 1 Batch 950 Loss 1.0629 Accuracy 0.4625\nEpoch 1 Batch 1000 Loss 1.0564 Accuracy 0.4638\nEpoch 1 Batch 1050 Loss 1.0498 Accuracy 0.4649\nEpoch 1 Batch 1100 Loss 1.0431 Accuracy 0.4656\nEpoch 1 Batch 1150 Loss 1.0371 Accuracy 0.4663\nEpoch 1 Batch 1200 Loss 1.0313 Accuracy 0.4671\nEpoch 1 Batch 1250 Loss 1.0252 Accuracy 0.4678\nEpoch 1 Batch 1300 Loss 1.0192 Accuracy 0.4685\nEpoch 1 Batch 1350 Loss 1.0132 Accuracy 0.4693\nEpoch 1 Batch 1400 Loss 1.0071 Accuracy 0.4701\nEpoch 1 Batch 1450 Loss 1.0029 Accuracy 0.4710\nEpoch 1 Batch 1500 Loss 0.9983 Accuracy 0.4719\nEpoch 1 Batch 1550 Loss 0.9930 Accuracy 0.4725\nEpoch 1 Batch 1600 Loss 0.9881 Accuracy 0.4731\nEpoch 1 Batch 1650 Loss 0.9826 Accuracy 0.4740\nEpoch 1 Batch 1700 Loss 0.9787 Accuracy 0.4747\nEpoch 1 Batch 1750 Loss 0.9747 Accuracy 0.4754\nEpoch 1 Batch 1800 Loss 0.9706 Accuracy 0.4759\nEpoch 1 Batch 1850 Loss 0.9665 Accuracy 0.4764\nEpoch 1 Batch 1900 Loss 0.9627 Accuracy 0.4768\nEpoch 1 Batch 1950 Loss 0.9589 Accuracy 0.4771\nEpoch 1 Batch 2000 Loss 0.9550 Accuracy 0.4776\nEpoch 1 Batch 2050 Loss 0.9514 Accuracy 0.4779\nEpoch 1 Batch 2100 Loss 0.9472 Accuracy 0.4783\nEpoch 1 Batch 2150 Loss 0.9436 Accuracy 0.4788\nEpoch 1 Batch 2200 Loss 0.9403 Accuracy 0.4792\nEpoch 1 Batch 2250 Loss 0.9367 Accuracy 0.4797\nEpoch 1 Batch 2300 Loss 0.9333 Accuracy 0.4800\nEpoch 1 Batch 2350 Loss 0.9300 Accuracy 0.4803\nEpoch 1 Batch 2400 Loss 0.9267 Accuracy 0.4807\nEpoch 1 Batch 2450 Loss 0.9236 Accuracy 0.4811\nEpoch 1 Batch 2500 Loss 0.9197 Accuracy 0.4814\nEpoch 1 Batch 2550 Loss 0.9166 Accuracy 0.4818\nEpoch 1 Batch 2600 Loss 0.9135 Accuracy 0.4821\nEpoch 1 Batch 2650 Loss 0.9108 Accuracy 0.4825\nEpoch 1 Batch 2700 Loss 0.9081 Accuracy 0.4829\nEpoch 1 Batch 2750 Loss 0.9062 Accuracy 0.4833\nEpoch 1 Batch 2800 Loss 0.9040 Accuracy 0.4836\nEpoch 1 Batch 2850 Loss 0.9019 Accuracy 0.4839\nEpoch 1 Batch 2900 Loss 0.8997 Accuracy 0.4842\nEpoch 1 Batch 2950 Loss 0.8981 Accuracy 0.4846\nEpoch 1 Batch 3000 Loss 0.8962 Accuracy 0.4849\nEpoch 1 Batch 3050 Loss 0.8947 Accuracy 0.4852\nEpoch 1 Batch 3100 Loss 0.8929 Accuracy 0.4855\nEpoch 1 Batch 3150 Loss 0.8913 Accuracy 0.4858\nEpoch 1 Batch 3200 Loss 0.8900 Accuracy 0.4862\nEpoch 1 Batch 3250 Loss 0.8887 Accuracy 0.4865\nEpoch 1 Batch 3300 Loss 0.8873 Accuracy 0.4869\nEpoch 1 Batch 3350 Loss 0.8861 Accuracy 0.4872\nEpoch 1 Batch 3400 Loss 0.8849 Accuracy 0.4875\nEpoch 1 Batch 3450 Loss 0.8836 Accuracy 0.4878\nEpoch 1 Batch 3500 Loss 0.8822 Accuracy 0.4881\nEpoch 1 Batch 3550 Loss 0.8812 Accuracy 0.4884\nEpoch 1 Batch 3600 Loss 0.8796 Accuracy 0.4888\nEpoch 1 Batch 3650 Loss 0.8784 Accuracy 0.4891\nEpoch 1 Batch 3700 Loss 0.8769 Accuracy 0.4893\nEpoch 1 Batch 3750 Loss 0.8759 Accuracy 0.4896\nEpoch 1 Batch 3800 Loss 0.8748 Accuracy 0.4900\nEpoch 1 Batch 3850 Loss 0.8736 Accuracy 0.4903\nEpoch 1 Batch 3900 Loss 0.8721 Accuracy 0.4906\nEpoch 1 Batch 3950 Loss 0.8708 Accuracy 0.4909\nEpoch 1 Batch 4000 Loss 0.8695 Accuracy 0.4912\nEpoch 1 Batch 4050 Loss 0.8683 Accuracy 0.4915\nEpoch 1 Batch 4100 Loss 0.8669 Accuracy 0.4918\nEpoch 1 Batch 4150 Loss 0.8656 Accuracy 0.4922\nEpoch 1 Batch 4200 Loss 0.8642 Accuracy 0.4926\nEpoch 1 Batch 4250 Loss 0.8629 Accuracy 0.4930\nEpoch 1 Batch 4300 Loss 0.8614 Accuracy 0.4934\nEpoch 1 Batch 4350 Loss 0.8602 Accuracy 0.4938\nEpoch 1 Batch 4400 Loss 0.8592 Accuracy 0.4942\nEpoch 1 Batch 4450 Loss 0.8577 Accuracy 0.4946\nEpoch 1 Batch 4500 Loss 0.8566 Accuracy 0.4950\nEpoch 1 Batch 4550 Loss 0.8556 Accuracy 0.4954\nEpoch 1 Batch 4600 Loss 0.8545 Accuracy 0.4958\nEpoch 1 Batch 4650 Loss 0.8535 Accuracy 0.4960\nEpoch 1 Batch 4700 Loss 0.8531 Accuracy 0.4962\nEpoch 1 Batch 4750 Loss 0.8533 Accuracy 0.4963\nEpoch 1 Batch 4800 Loss 0.8541 Accuracy 0.4964\nEpoch 1 Batch 4850 Loss 0.8551 Accuracy 0.4963\nEpoch 1 Batch 4900 Loss 0.8568 Accuracy 0.4962\nEpoch 1 Batch 4950 Loss 0.8584 Accuracy 0.4961\nEpoch 1 Batch 5000 Loss 0.8600 Accuracy 0.4958\nEpoch 1 Batch 5050 Loss 0.8619 Accuracy 0.4956\nEpoch 1 Batch 5100 Loss 0.8639 Accuracy 0.4954\nEpoch 1 Batch 5150 Loss 0.8661 Accuracy 0.4951\nEpoch 1 Batch 5200 Loss 0.8683 Accuracy 0.4948\nEpoch 1 Batch 5250 Loss 0.8704 Accuracy 0.4945\nEpoch 1 Batch 5300 Loss 0.8726 Accuracy 0.4942\nEpoch 1 Batch 5350 Loss 0.8746 Accuracy 0.4939\nEpoch 1 Batch 5400 Loss 0.8768 Accuracy 0.4936\nEpoch 1 Batch 5450 Loss 0.8789 Accuracy 0.4933\nEpoch 1 Batch 5500 Loss 0.8811 Accuracy 0.4930\nEpoch 1 Batch 5550 Loss 0.8830 Accuracy 0.4928\nEpoch 1 Batch 5600 Loss 0.8849 Accuracy 0.4925\nEpoch 1 Batch 5650 Loss 0.8868 Accuracy 0.4922\nEpoch 1 Batch 5700 Loss 0.8889 Accuracy 0.4920\nEpoch 1 Batch 5750 Loss 0.8909 Accuracy 0.4916\nEpoch 1 Batch 5800 Loss 0.8930 Accuracy 0.4913\nEpoch 1 Batch 5850 Loss 0.8950 Accuracy 0.4910\nEpoch 1 Batch 5900 Loss 0.8969 Accuracy 0.4906\nEpoch 1 Batch 5950 Loss 0.8988 Accuracy 0.4903\nEpoch 1 Batch 6000 Loss 0.9006 Accuracy 0.4899\nEpoch 1 Batch 6050 Loss 0.9023 Accuracy 0.4896\nEpoch 1 Batch 6100 Loss 0.9041 Accuracy 0.4893\nEpoch 1 Batch 6150 Loss 0.9057 Accuracy 0.4890\nEpoch 1 Batch 6200 Loss 0.9075 Accuracy 0.4886\nEpoch 1 Batch 6250 Loss 0.9091 Accuracy 0.4884\nEpoch 1 Batch 6300 Loss 0.9107 Accuracy 0.4881\nEpoch 1 Batch 6350 Loss 0.9121 Accuracy 0.4878\nEpoch 1 Batch 6400 Loss 0.9134 Accuracy 0.4876\nSaving checkpont for epoch 1 at data/ckpt-10\ntime taken for 1 epoch: 2706.164709329605 secs\n\n"
        }
      ],
      "execution_count": 27,
      "metadata": {
        "id": "d7q2LuvbE8xM",
        "gather": {
          "logged": 1683647440339
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluation"
      ],
      "metadata": {
        "id": "L2vY9ogwzFW0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(inp_sentence):\n",
        "    inp_sentence = \\\n",
        "        [VOCAB_SIZE_EN-2] + tokenizer_en.encode(inp_sentence) + [VOCAB_SIZE_EN-1]\n",
        "    enc_input = tf.expand_dims(inp_sentence, axis=0)\n",
        "\n",
        "    output = tf.expand_dims([VOCAB_SIZE_ES-2], axis=0)\n",
        "\n",
        "    for _ in range(MAX_LENGTH):\n",
        "        predictions = transformer(enc_input, output, False) # (1, seq_length, vocab_size_es)\n",
        "\n",
        "        prediction = predictions[:, -1:, :]\n",
        "\n",
        "        predicted_id = tf.cast(tf.argmax(prediction, axis=-1), tf.int32)\n",
        "\n",
        "        if predicted_id == VOCAB_SIZE_ES-1:\n",
        "            return tf.squeeze(output, axis=0)\n",
        "        \n",
        "        output = tf.concat([output, predicted_id], axis=-1)\n",
        "    \n",
        "    return tf.squeeze(output, axis=0)"
      ],
      "outputs": [],
      "execution_count": 28,
      "metadata": {
        "id": "umPNHaoRGTxj",
        "gather": {
          "logged": 1683647441800
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def translate(sentence):\n",
        "    output = evaluate(sentence).numpy()\n",
        "\n",
        "    predicted_sentence = tokenizer_es.decode(\n",
        "        [i for i in output if i < VOCAB_SIZE_ES-2]\n",
        "    )\n",
        "\n",
        "    print(\"Input: {}\".format(sentence))\n",
        "    print(\"Predicted translation: {}\".format(predicted_sentence))"
      ],
      "outputs": [],
      "execution_count": 29,
      "metadata": {
        "id": "ZkYA-uifz2J4",
        "gather": {
          "logged": 1683647443548
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "translate(\"This is great.\")\r\n",
        "translate(\"This is a really powerful tool!\")\r\n",
        "translate(\"We should solve this problem.\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Input: This is great.\nPredicted translation: Esto es muy bueno.\nInput: This is a really powerful tool!\nPredicted translation: ¡Es una herramienta realmente poderosa!\nInput: We should solve this problem.\nPredicted translation: Debemos resolver este problema.\n"
        }
      ],
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TQS6keta0IMw",
        "outputId": "4c9c5b38-c33d-4d92-f323-65f4cb48ecf4",
        "gather": {
          "logged": 1683647559563
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "translate(\"We propose a new simple network architecture, the Transformer, based solely on attention mechanisms, dispensing with recurrence and convolutions entirely.\")\r\n",
        "translate(\"Experiments on two machine translation tasks show these models to be superior in quality while being more parallelizable and requiring signiﬁcantly less time to train.\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Input: We propose a new simple network architecture, the Transformer, based solely on attention mechanisms, dispensing with recurrence and convolutions entirely.\nPredicted translation: Proponemos una nueva cuestión de alta importancia, la reforma de las transiciones.\nInput: Experiments on two machine translation tasks show these models to be superior in quality while being more parallelizable and requiring signiﬁcantly less time to train.\nPredicted translation: Las experiencias de dos tareas de la producción de hoy en día son más fuertes y más fuertes.\n"
        }
      ],
      "execution_count": 33,
      "metadata": {
        "id": "CIGtLSe7VfPg",
        "gather": {
          "logged": 1683647584943
        }
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python38-azureml",
      "language": "python",
      "display_name": "Python 3.8 - AzureML"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.5",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "accelerator": "GPU",
    "microsoft": {
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      },
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "kernel_info": {
      "name": "python38-azureml"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}